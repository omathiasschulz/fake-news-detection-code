
# METRICAS
loss; accuracy_model(%); accuracy_detection(%); rmse; precision; recall; f1-score; confusion_matrix;



5.1  MODELO MLP

Esse capítulo apresenta os treinamentos e resultados das diferentes configurações realizadas com o modelo MLP (Multilayer Perceptron).

Todos os testes apresentados abaixo com o modelo MLP foram realizadas com alguns configurações fixas. Dessa forma, as configurações possuem de forma fixa três camadas, uma camada de entrada, uma camada intermediária e a camada de saída. Além disso, a quantidade de épocas é igual à 50, o kernel initializer utilizado é o uniform e o algoritmo de otimização é o ADAM.

O primeiro teste realizado, com base no dataset com notícias com 50 palavras, foi utilizando funções de ativações variadas nas camadas, podendo variar entre sigmoid, tanh, relu e elu. Como os modelos possuem três camadas, a quantidade de neurônios da primeira camada é 12, da segunda é 8 e da terceira é 1. A tabela abaixo apresenta os resultados das 64 configurações obtidas.

sigmoid;sigmoid;sigmoid;0.1337;95.4619;94.8198;0.0787;0.9480;0.9481;0.9481;3419-180-175-3079;
sigmoid;sigmoid;tanh;7.9250;48.6224;52.5171;0.6049;0.2626;0.5000;0.3443;3599-0-3254-0;
sigmoid;sigmoid;relu;0.1624;95.2998;94.1777;0.1004;0.9417;0.9415;0.9416;3405-194-205-3049;
sigmoid;sigmoid;elu;7.9250;48.6224;52.5171;0.5449;0.2626;0.5000;0.3443;3599-0-3254-0;
sigmoid;tanh;sigmoid;0.1528;94.1653;94.0026;0.0870;0.9408;0.9392;0.9398;3442-157-254-3000;
sigmoid;tanh;tanh;7.9250;48.6224;52.5171;0.5191;0.2626;0.5000;0.3443;3599-0-3254-0;
sigmoid;tanh;relu;7.9250;48.6224;52.5171;0.5138;0.2626;0.5000;0.3443;3599-0-3254-0;
sigmoid;tanh;elu;7.9250;48.6224;52.5171;0.5193;0.2626;0.5000;0.3443;3599-0-3254-0;
sigmoid;relu;sigmoid;0.1373;94.8136;94.2069;0.0833;0.9417;0.9426;0.9420;3354-245-152-3102;
sigmoid;relu;tanh;7.9250;48.6224;52.5171;0.5236;0.2626;0.5000;0.3443;3599-0-3254-0;
sigmoid;relu;relu;0.1705;94.3274;86.6774;0.2053;0.6229;0.5748;0.5960;3432-165-257-2508;
sigmoid;relu;elu;0.3040;87.1961;88.3263;0.1988;0.6007;0.5855;0.5875;3523-76-715-2530;
sigmoid;elu;sigmoid;0.1363;94.8136;94.2945;0.0833;0.9426;0.9431;0.9428;3383-216-175-3079;
sigmoid;elu;tanh;0.1744;95.1378;94.2507;0.1296;0.9422;0.9426;0.9424;3383-216-178-3076;
sigmoid;elu;relu;0.1972;94.1653;90.3254;0.1798;0.6231;0.6004;0.6108;3430-166-274-2760;
sigmoid;elu;elu;0.2556;91.0859;91.9305;0.2056;0.9253;0.9165;0.9185;3497-102-451-2803;
tanh;sigmoid;sigmoid;0.1280;95.1378;94.7906;0.0755;0.9477;0.9488;0.9479;3352-247-110-3144;
tanh;sigmoid;tanh;7.9250;48.6224;52.5171;0.5904;0.2626;0.5000;0.3443;3599-0-3254-0;
tanh;sigmoid;relu;7.9250;48.6224;52.5171;0.5138;0.2626;0.5000;0.3443;3599-0-3254-0;
tanh;sigmoid;elu;0.1623;94.6515;94.0172;0.1451;0.9405;0.9396;0.9400;3424-175-235-3019;
tanh;tanh;sigmoid;0.1237;95.4619;94.8344;0.0747;0.9480;0.9486;0.9483;3393-206-148-3106;
tanh;tanh;tanh;0.1730;94.4895;79.7315;0.2524;0.6216;0.5374;0.5667;0-0-938-2275;
tanh;tanh;relu;0.2046;95.2998;94.4842;0.1200;0.9447;0.9447;0.9447;3407-192-186-3068;
tanh;tanh;elu;0.1771;94.9757;91.7700;0.2319;0.6283;0.6127;0.6202;0-0-181-3212;
tanh;relu;sigmoid;0.1367;95.1378;95.3597;0.0685;0.9533;0.9537;0.9535;3426-173-145-3109;
tanh;relu;tanh;0.2698;95.7861;93.5065;0.2175;0.6336;0.6241;0.6287;0-0-112-3294;
tanh;relu;relu;0.2075;94.8136;93.5065;0.1647;0.6295;0.6229;0.6262;3415-184-193-2993;
tanh;relu;elu;0.1917;95.2998;94.6155;0.2290;0.6341;0.6306;0.6323;3422-177-154-3062;
tanh;elu;sigmoid;0.1245;95.4619;95.3013;0.0722;0.9527;0.9534;0.9529;3403-196-126-3128;
tanh;elu;tanh;0.3194;95.2998;59.9008;0.3803;0.6042;0.4105;0.4582;0-0-2411-1018;
tanh;elu;relu;0.2717;95.9481;94.7614;0.1204;0.9473;0.9477;0.9475;3403-196-163-3091;
tanh;elu;elu;0.3443;90.1135;76.9152;0.3363;0.6023;0.5151;0.5553;0-0-998-2531;
relu;sigmoid;sigmoid;0.1360;95.6240;95.0970;0.0769;0.9508;0.9509;0.9509;3428-171-165-3089;
relu;sigmoid;tanh;0.1735;94.8136;94.5425;0.0972;0.9457;0.9449;0.9452;3439-160-214-3040;
relu;sigmoid;relu;7.9250;48.6224;52.5171;0.5138;0.2626;0.5000;0.3443;3599-0-3254-0;
relu;sigmoid;elu;7.9250;48.6224;52.5171;0.5514;0.2626;0.5000;0.3443;3599-0-3254-0;
relu;tanh;sigmoid;0.1339;95.6240;96.3374;0.0581;0.9631;0.9635;0.9633;3456-143-108-3146;
relu;tanh;tanh;0.2556;94.8136;88.2825;0.1804;0.6330;0.5908;0.6102;0-0-481-2945;
relu;tanh;relu;0.1707;95.9481;95.5348;0.1264;0.9552;0.9553;0.9552;3442-157-149-3105;
relu;tanh;elu;0.2285;94.1653;83.1315;0.2711;0.4615;0.4190;0.4347;0-0-638-2539;
relu;relu;sigmoid;0.6967;48.6224;52.5171;0.5008;0.2626;0.5000;0.3443;3599-0-3254-0;
relu;relu;tanh;0.2238;95.6240;88.5598;0.1944;0.6392;0.5930;0.6139;0-0-522-2922;
relu;relu;relu;0.1419;95.1378;82.5040;0.2259;0.6284;0.5456;0.5810;3423-175-150-2231;
relu;relu;elu;0.1799;94.8136;91.7263;0.2294;0.4711;0.4591;0.4649;0-0-130-3242;
relu;elu;sigmoid;0.1241;95.6240;96.2060;0.0605;0.9617;0.9624;0.9620;3439-160-100-3154;
relu;elu;tanh;0.2140;95.6240;83.9195;0.2075;0.6275;0.5632;0.5907;0-0-737-2640;
relu;elu;relu;0.1978;95.1378;91.6533;0.1653;0.6323;0.6100;0.6209;3398-200-135-2883;
relu;elu;elu;0.1622;96.2723;77.1195;0.2952;0.6235;0.5201;0.5592;0-0-1193-2165;
elu;sigmoid;sigmoid;0.1397;94.9757;94.6739;0.0818;0.9465;0.9467;0.9466;3407-192-173-3081;
elu;sigmoid;tanh;0.1404;95.2998;95.7245;0.0829;0.9569;0.9577;0.9572;3417-182-111-3143;
elu;sigmoid;relu;7.9250;48.6224;52.5171;0.5138;0.2626;0.5000;0.3443;3599-0-3254-0;
elu;sigmoid;elu;0.1996;95.6240;94.9511;0.1517;0.9497;0.9491;0.9494;3446-153-193-3061;
elu;tanh;sigmoid;0.1350;95.4619;94.9657;0.0735;0.9495;0.9496;0.9495;3423-176-169-3085;
elu;tanh;tanh;0.2233;94.4895;61.0390;0.3826;0.6082;0.4186;0.4547;0-0-2210-1011;
elu;tanh;relu;0.1975;95.6240;94.3966;0.1628;0.6335;0.6295;0.6314;3373-226-110-3096;
elu;tanh;elu;0.1784;95.7861;75.0912;0.3228;0.6248;0.5070;0.5516;0-0-1371-2052;
elu;relu;sigmoid;0.1325;94.8136;94.1777;0.0837;0.9415;0.9424;0.9417;3347-252-147-3107;
elu;relu;tanh;0.1871;95.2998;95.1262;0.1335;0.6343;0.6349;0.6342;0-0-1-3347;
elu;relu;relu;0.5905;90.2755;90.7924;0.1522;0.9203;0.9038;0.9064;3547-52-579-2675;
elu;relu;elu;7.9250;48.6224;52.5171;0.5213;0.2626;0.5000;0.3443;3599-0-3254-0;
elu;elu;sigmoid;0.1234;95.7861;95.3159;0.0693;0.9528;0.9534;0.9531;3412-187-134-3120;
elu;elu;tanh;0.2687;95.2998;57.4493;0.4138;0.6120;0.3956;0.4332;0-0-2572-784;
elu;elu;relu;7.9250;48.6224;52.5171;0.5138;0.2626;0.5000;0.3443;3599-0-3254-0;
elu;elu;elu;0.2025;94.8136;78.7246;0.2882;0.6221;0.5302;0.5663;0-0-1063-2291;

Como observado na tabela acima, mesmo sendo o primeiro teste já existem ótimos resultados, por exemplo um resultado com acurácia na detecção de 96.3374% e RMSE de 0.0581. Os três melhores resultados obtidos são apresentados abaixo:

relu;tanh;sigmoid;0.1339;95.6240;96.3374;0.0581;0.9631;0.9635;0.9633;3456-143-108-3146;
elu;elu;sigmoid;0.1234;95.7861;95.3159;0.0693;0.9528;0.9534;0.9531;3412-187-134-3120;
relu;elu;sigmoid;0.1241;95.6240;96.2060;0.0605;0.9617;0.9624;0.9620;3439-160-100-3154;

O segundo teste é realizado pegando os três melhores modelos do primeiro teste e utilizado a quantidade de neurônios variada.

# MODELO MLP - TESTES COM QUANTIDADE DE NEURÔNIOS VARIADA - MODELO 01

# Teste MLP - 2021-02-18 11:45:23.438448 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 128, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.4219; accuracy_model(%): 94.9757; accuracy_detection(%): 98.1322; rmse: 0.0550; precision: 0.9812; recall: 0.9813; f1-score: 0.9813; confusion_matrix: 3533-66-62-3192;
Tem o menor RMSE



# MODELO MLP - TESTES COM QUANTIDADE DE NEURÔNIOS VARIADA - MODELO 02

# Teste MLP - 2021-02-19 07:43:09.928320 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 200, "activation": "elu"}, {"qtd_neurons": 300, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1774; accuracy_model(%): 94.9757; accuracy_detection(%): 96.2644; rmse: 0.0608; precision: 0.9623; recall: 0.9631; f1-score: 0.9626; confusion_matrix: 3433-166-90-3164;
Tem o menor RMSE



# MODELO MLP - TESTES COM QUANTIDADE DE NEURÔNIOS VARIADA - MODELO 03

# Teste MLP - 2021-02-19 08:35:47.029355 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 75, "activation": "relu"}, {"qtd_neurons": 128, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2686; accuracy_model(%): 95.6240; accuracy_detection(%): 98.0009; rmse: 0.0476; precision: 0.9800; recall: 0.9799; f1-score: 0.9800; confusion_matrix: 3533-66-71-3183;
Tem o menor RMSE



# MODELO MLP - TESTES COM BATCH SIZE VARIADO

# Teste MLP - 2021-02-20 09:31:10.334016 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 128, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2595; accuracy_model(%): 95.9481; accuracy_detection(%): 98.2198; rmse: 0.0429; precision: 0.9823; recall: 0.9820; f1-score: 0.9821; confusion_matrix: 3550-49-73-3181;
Tem o menor RMSE



# MODELO MLP - TESTES COM BATCH SIZE VARIADO - MODELO 02

# Teste MLP - 2021-02-20 09:38:47.421948 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 200, "activation": "elu"}, {"qtd_neurons": 300, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2410; accuracy_model(%): 94.0032; accuracy_detection(%): 96.9356; rmse: 0.0631; precision: 0.9690; recall: 0.9699; f1-score: 0.9693; confusion_matrix: 3451-148-62-3192;
Tem o melhor f1-score



# MODELO MLP - TESTES COM BATCH SIZE VARIADO - MODELO 03

# Teste MLP - 2021-02-20 09:48:54.356669 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 75, "activation": "relu"}, {"qtd_neurons": 128, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.3366; accuracy_model(%): 94.9757; accuracy_detection(%): 97.7966; rmse: 0.0528; precision: 0.9778; recall: 0.9781; f1-score: 0.9779; confusion_matrix: 3511-88-63-3191;
Todos resultados foram semelhantes, com as métricas semelhantes, esse possui o melhor RMSE






# MODELO MLP - TESTES COM FUNÇÕES DE ATIVAÇÃO VARIADAS - 100 PALAVRAS

# 1º
# Teste MLP - 2021-02-20 10:38:58.807306 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1483; accuracy_model(%): 95.0538; accuracy_detection(%): 95.4123; rmse: 0.0696; precision: 0.9402; recall: 0.9550; f1-score: 0.9471; confusion_matrix: 3407-169-68-1522;

# 2º
# Teste MLP - 2021-02-20 10:40:45.977257 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1444; accuracy_model(%): 94.6237; accuracy_detection(%): 95.4704; rmse: 0.0701; precision: 0.9434; recall: 0.9516; f1-score: 0.9473; confusion_matrix: 3432-144-90-1500;

# 3º
# Teste MLP - 2021-02-20 10:39:52.312337 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "relu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1409; accuracy_model(%): 94.4086; accuracy_detection(%): 94.8509; rmse: 0.0775; precision: 0.9338; recall: 0.9485; f1-score: 0.9406; confusion_matrix: 3392-184-82-1508;

















# METRICAS - Acurracy, Precision, Recall e F1 Score
https://medium.com/@vilsonrodrigues/machine-learning-o-que-s%C3%A3o-acurracy-precision-recall-e-f1-score-f16762f165b0

# BATCH SIZE
Neste experimento, vamos investigar o efeito do tamanho do lote (Batch Size) na dinâmica de treinamento. Tamanho do lote (Batch Size) é um termo usado em aprendizado de máquina e refere-se ao número de exemplos de treinamento usados em uma iteração. O Batch Size pode ser uma das três opções:

batch mode: onde o tamanho do lote é igual ao conjunto de dados total, tornando os valores de iteração e épocas equivalentes.
mini-batch mode: onde o tamanho do lote é maior que um, mas menor que o tamanho total do conjunto de dados. Geralmente, um número que pode ser dividido no tamanho total do conjunto de dados.
stochastic mode: onde o tamanho do lote é igual a um. Portanto, o gradiente e os parâmetros da rede neural são atualizados após cada amostra.

http://deeplearningbook.com.br/o-efeito-do-batch-size-no-treinamento-de-redes-neurais-artificiais/

# 5.2  MODELO LSTM
Esse capítulo apresenta o treinamento e resultado das diferentes configurações realizadas com o modelo LSTM (Long Short Term Memory).

MODELO LSTM
A camada de Dropout serve para mitigar problemas de sobreajuste
Uma camada LSTM antes de cada camada LSTM subsequente deve retornar a sequência
O que pode ser feito definindo o parâmetro "return_sequences = True" na(s) camada(s) anterior(es)
