


MELHORES MODELOS - RNA MLP - DATASET 50 PALAVRAS

MODELO 01
# Teste MLP - 2021-02-18 10:20:50.444755 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1339; accuracy_model(%): 95.6240; accuracy_detection(%): 96.3374; rmse: 0.0581; precision: 0.9631; recall: 0.9635; f1-score: 0.9633; confusion_matrix: 3456-143-108-3146;

MODELO 02
# Teste MLP - 2021-02-18 10:27:42.153625 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "elu"}, {"qtd_neurons": 8, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1234; accuracy_model(%): 95.7861; accuracy_detection(%): 95.3159; rmse: 0.0693; precision: 0.9528; recall: 0.9534; f1-score: 0.9531; confusion_matrix: 3412-187-134-3120;

MODELO 03
# Teste MLP - 2021-02-18 10:23:06.825242 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1241; accuracy_model(%): 95.6240; accuracy_detection(%): 96.2060; rmse: 0.0605; precision: 0.9617; recall: 0.9624; f1-score: 0.9620; confusion_matrix: 3439-160-100-3154;

MODELO 04
# Teste MLP - 2021-02-18 11:45:23.438448 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 128, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.4219; accuracy_model(%): 94.9757; accuracy_detection(%): 98.1322; rmse: 0.0550; precision: 0.9812; recall: 0.9813; f1-score: 0.9813; confusion_matrix: 3533-66-62-3192;

MODELO 05
# Teste MLP - 2021-02-19 07:43:09.928320 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 200, "activation": "elu"}, {"qtd_neurons": 300, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1774; accuracy_model(%): 94.9757; accuracy_detection(%): 96.2644; rmse: 0.0608; precision: 0.9623; recall: 0.9631; f1-score: 0.9626; confusion_matrix: 3433-166-90-3164;

MODELO 06
# Teste MLP - 2021-02-19 08:35:47.029355 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 75, "activation": "relu"}, {"qtd_neurons": 128, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2686; accuracy_model(%): 95.6240; accuracy_detection(%): 98.0009; rmse: 0.0476; precision: 0.9800; recall: 0.9799; f1-score: 0.9800; confusion_matrix: 3533-66-71-3183;

MODELO 07
# Teste MLP - 2021-02-20 09:31:10.334016 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 128, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2595; accuracy_model(%): 95.9481; accuracy_detection(%): 98.2198; rmse: 0.0429; precision: 0.9823; recall: 0.9820; f1-score: 0.9821; confusion_matrix: 3550-49-73-3181;

MODELO 08
# Teste MLP - 2021-02-20 09:38:47.421948 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 200, "activation": "elu"}, {"qtd_neurons": 300, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2410; accuracy_model(%): 94.0032; accuracy_detection(%): 96.9356; rmse: 0.0631; precision: 0.9690; recall: 0.9699; f1-score: 0.9693; confusion_matrix: 3451-148-62-3192;

MODELO 09
# Teste MLP - 2021-02-20 09:48:54.356669 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 75, "activation": "relu"}, {"qtd_neurons": 128, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.3366; accuracy_model(%): 94.9757; accuracy_detection(%): 97.7966; rmse: 0.0528; precision: 0.9778; recall: 0.9781; f1-score: 0.9779; confusion_matrix: 3511-88-63-3191;

MELHOR MODELO - MODELO 07
# Teste MLP - 2021-02-20 09:31:10.334016 - dataset_50_palavras.csv
{"epochs": 50, "batch_size": 2, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 128, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.2595; accuracy_model(%): 95.9481; accuracy_detection(%): 98.2198; rmse: 0.0429; precision: 0.9823; recall: 0.9820; f1-score: 0.9821; confusion_matrix: 3550-49-73-3181;



MELHORES MODELOS - RNA MLP - DATASET 100 PALAVRAS

MODELO 01
# Teste MLP - 2021-02-20 10:38:58.807306 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1483; accuracy_model(%): 95.0538; accuracy_detection(%): 95.4123; rmse: 0.0696; precision: 0.9402; recall: 0.9550; f1-score: 0.9471; confusion_matrix: 3407-169-68-1522;

MODELO 02
# Teste MLP - 2021-02-20 10:40:45.977257 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1444; accuracy_model(%): 94.6237; accuracy_detection(%): 95.4704; rmse: 0.0701; precision: 0.9434; recall: 0.9516; f1-score: 0.9473; confusion_matrix: 3432-144-90-1500;

MODELO 03
# Teste MLP - 2021-02-20 10:39:52.312337 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 12, "activation": "relu"}, {"qtd_neurons": 8, "activation": "relu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1409; accuracy_model(%): 94.4086; accuracy_detection(%): 94.8509; rmse: 0.0775; precision: 0.9338; recall: 0.9485; f1-score: 0.9406; confusion_matrix: 3392-184-82-1508;

MODELO 04 - Melhor RMSE - Um dos melhores F1 Score
# Teste MLP - 2021-02-20 11:55:01.882520 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 30, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.3711; accuracy_model(%): 94.1935; accuracy_detection(%): 97.9868; rmse: 0.0646; precision: 0.9761; recall: 0.9767; f1-score: 0.9764; confusion_matrix: 3522-54-50-1540;

MODELO 05 - Segundo melhor RMSE - Um dos melhores F1 Score
# Teste MLP - 2021-02-20 16:23:52.095160 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 150, "activation": "relu"}, {"qtd_neurons": 300, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.5468; accuracy_model(%): 93.9785; accuracy_detection(%): 97.6965; rmse: 0.0635; precision: 0.9717; recall: 0.9745; f1-score: 0.9730; confusion_matrix: 3508-68-51-1539;

MODELO 06 - Melhor RMSE - Melhor F1 Score
# Teste MLP - 2021-02-20 17:21:59.825503 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 200, "activation": "relu"}, {"qtd_neurons": 90, "activation": "relu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.3015; accuracy_model(%): 96.3441; accuracy_detection(%): 98.3353; rmse: 0.0436; precision: 0.9792; recall: 0.9819; f1-score: 0.9805; confusion_matrix: 3525-51-35-1555;

MODELO 07 - Melhor RMSE - Melhor F1 Score
# Teste MLP - 2021-03-04 09:46:16.627728 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 25, "layers": [{"qtd_neurons": 300, "activation": "relu"}, {"qtd_neurons": 30, "activation": "tanh"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.3001; accuracy_model(%): 93.3333; accuracy_detection(%): 97.6771; rmse: 0.0715; precision: 0.9720; recall: 0.9736; f1-score: 0.9728; confusion_matrix: 3511-65-55-1535;

MODELO 08 - Melhor RMSE
# Teste MLP - 2021-03-04 10:00:01.919535 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 5, "layers": [{"qtd_neurons": 150, "activation": "relu"}, {"qtd_neurons": 300, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.4219; accuracy_model(%): 93.9785; accuracy_detection(%): 97.6965; rmse: 0.0610; precision: 0.9691; recall: 0.9776; f1-score: 0.9732; confusion_matrix: 3490-86-33-1557;

MODELO 09 - Melhor RMSE
# Teste MLP - 2021-03-04 10:32:38.507376 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 5, "layers": [{"qtd_neurons": 200, "activation": "relu"}, {"qtd_neurons": 90, "activation": "elu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.5036; accuracy_model(%): 92.4731; accuracy_detection(%): 97.8126; rmse: 0.0748; precision: 0.9759; recall: 0.9727; f1-score: 0.9742; confusion_matrix: 3529-47-66-1524;

MELHOR MODELO - MODELO 06
# Teste MLP - 2021-02-20 17:21:59.825503 - dataset_100_palavras.csv
{"epochs": 50, "batch_size": 10, "layers": [{"qtd_neurons": 200, "activation": "relu"}, {"qtd_neurons": 90, "activation": "relu"}, {"qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.3015; accuracy_model(%): 96.3441; accuracy_detection(%): 98.3353; rmse: 0.0436; precision: 0.9792; recall: 0.9819; f1-score: 0.9805; confusion_matrix: 3525-51-35-1555;



MELHORES MODELOS - RNA LSTM - DATASET 50 PALAVRAS

=> return_sequences
As redes LSTM podem ser empilhadas em Keras da mesma maneira que outros tipos de camada podem ser empilhados.
Uma adição à configuração necessária é que uma camada LSTM antes de cada camada LSTM subsequente deve retornar a sequência.
Isso pode ser feito definindo o parâmetro return_sequences na camada como True.

=> dropout
O dropout é utilizado para evitar problemas de sobreajuste.
Exemplo: {'type': Model.LAYER_DROPOUT, 'value': 0.2},
Overfitting (sobre-ajuste) é um termo usado em estatística para descrever quando um modelo estatístico se ajusta muito bem ao conjunto de dados anteriormente observado, mas se mostra ineficaz para prever novos resultados.

MODELO 01
# Teste LSTM - 2021-03-06 14:47:15.775823 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 12, "activation": "elu", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 8, "activation": "relu"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1720; accuracy_model(%): 93.6791; accuracy_detection(%): 92.4267; rmse: 0.0895; precision: 0.9241; recall: 0.9251; f1-score: 0.9242; confusion_matrix: 3271-328-191-3063;

MODELO 02
# Teste LSTM - 2021-03-06 14:43:02.950016 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 12, "activation": "elu", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 8, "activation": "tanh"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1764; accuracy_model(%): 94.0032; accuracy_detection(%): 93.0541; rmse: 0.0945; precision: 0.9311; recall: 0.9297; f1-score: 0.9303; confusion_matrix: 3404-195-281-2973;

MODELO 03
# Teste LSTM - 2021-03-06 14:18:25.083458 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 12, "activation": "tanh", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 8, "activation": "elu"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1636; accuracy_model(%): 94.0032; accuracy_detection(%): 92.9228; rmse: 0.0945; precision: 0.9292; recall: 0.9288; f1-score: 0.9290; confusion_matrix: 3372-227-258-2996;

MODELO 04
# Teste LSTM - 2021-03-06 21:15:01.879701 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 150, "activation": "elu", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 2, "activation": "relu"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1706; accuracy_model(%): 94.8136; accuracy_detection(%): 94.0902; rmse: 0.0932; precision: 0.9409; recall: 0.9405; f1-score: 0.9407; confusion_matrix: 3411-188-217-3037;

MODELO 05
# Teste LSTM - 2021-03-07 06:58:24.219357 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 300, "activation": "elu", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 90, "activation": "tanh"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1489; accuracy_model(%): 95.1378; accuracy_detection(%): 94.5425; rmse: 0.0737; precision: 0.9461; recall: 0.9447; f1-score: 0.9452; confusion_matrix: 3455-144-230-3024;

MODELO 06
# Teste LSTM - 2021-03-07 14:16:46.582306 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 300, "activation": "tanh", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 50, "activation": "elu"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1443; accuracy_model(%): 94.3274; accuracy_detection(%): 95.0533; rmse: 0.0746; precision: 0.9505; recall: 0.9503; f1-score: 0.9504; confusion_matrix: 3437-162-177-3077;

MODELO 07
# Teste LSTM - 2021-03-08 23:46:37.948996 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 5, "layers": [{"qtd_neurons": 150, "activation": "elu", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 2, "activation": "relu"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1660; accuracy_model(%): 94.6515; accuracy_detection(%): 94.5571; rmse: 0.0863; precision: 0.9452; recall: 0.9462; f1-score: 0.9455; confusion_matrix: 3362-237-136-3118;

MODELO 08
# Teste LSTM - 2021-03-09 06:59:48.518687 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 32, "layers": [{"qtd_neurons": 300, "activation": "elu", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 90, "activation": "tanh"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1611; accuracy_model(%): 94.0032; accuracy_detection(%): 94.7614; rmse: 0.0929; precision: 0.9477; recall: 0.9472; f1-score: 0.9475; confusion_matrix: 3438-161-198-3056;

MODELO 09
# Teste LSTM - 2021-03-09 03:02:28.189560 - dataset_50_palavras.csv
{"epochs": 20, "batch_size": 1, "layers": [{"qtd_neurons": 300, "activation": "tanh", "return_sequences": true}, {"type": "lstm", "qtd_neurons": 50, "activation": "elu"}, {"type": "dense", "qtd_neurons": 1, "activation": "sigmoid"}]}
métricas: loss: 0.1483; accuracy_model(%): 94.4895; accuracy_detection(%): 95.2430; rmse: 0.0735; precision: 0.9521; recall: 0.9528; f1-score: 0.9523; confusion_matrix: 3404-195-131-3123;





[TODO]
 - Finalizar o Resumo do artigo apresentando a melhor configuração LSTM;
 - Finalizar os testes com o modelo LSTM;
 - Construir o tópico de Conclusão;
 - Ler o artigo;
 - Ajustar o abstract;

 - Ta faltando ainda a Folha de aprovação, eu sei se já posso colocar ou só é colocado depois da apresentação do TCC. Porque eu também não sei quem serão os avaliadores
